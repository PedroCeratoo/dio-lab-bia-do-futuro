# ğŸ‡§ğŸ‡·ğŸ’¸ ApertÃ´ â€“ Consultor Inteligente de Extratos com LLM Local

## ğŸ“Œ Sobre o Projeto

O **ApertÃ´** Ã© um agente financeiro que analisa extratos bancÃ¡rios em CSV utilizando um modelo de linguagem rodando localmente via **Ollama (llama3.2)**.

Ele atua como um consultor dos seus extratos, permitindo que vocÃª faÃ§a perguntas sobre seu histÃ³rico financeiro e receba respostas:

- Baseadas exclusivamente nos dados fornecidos
- Sem alucinaÃ§Ãµes
- Sem extrapolaÃ§Ãµes
- Com linguagem formal e profissional

---

## ğŸ¯ Objetivo

Transformar extratos bancÃ¡rios brutos em respostas inteligentes e confiÃ¡veis atravÃ©s de um LLM local.

O agente Ã© capaz de responder perguntas como:

- Quanto gastei no mÃªs?
- Quais foram meus maiores gastos?
- Existe aumento nas despesas?
- Quais transaÃ§Ãµes aconteceram em determinado perÃ­odo?
- Tenho recorrÃªncia em algum tipo de gasto?

Sempre com base exclusiva nos dados carregados.

---

## ğŸ§  Funcionamento do Sistema

### ğŸ”„ Fluxo da AplicaÃ§Ã£o

1. A aplicaÃ§Ã£o inicia via **Streamlit**
2. Todos os arquivos `.csv` dentro da pasta `data/` sÃ£o lidos automaticamente
3. Os dados sÃ£o convertidos para texto estruturado
4. O conteÃºdo Ã© injetado no contexto do prompt
5. A pergunta do usuÃ¡rio Ã© enviada ao modelo `llama3.2` via Ollama
6. O modelo retorna a resposta com base apenas nos extratos

---

## ğŸ“‚ Leitura AutomÃ¡tica dos Dados

O sistema:

- Percorre a pasta `data/`
- LÃª todos os arquivos `.csv`
- Converte cada DataFrame em string
- Consolida tudo em um Ãºnico bloco de contexto

Isso permite mÃºltiplos extratos (ex: Nov/2025 a Jan/2026).

---

## ğŸ¤– Modelo Utilizado

- LLM rodando localmente via **Ollama**
- Modelo: `llama3.2`

Endpoint utilizado:

